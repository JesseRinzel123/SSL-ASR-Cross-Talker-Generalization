{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phonecodes import phonecodes\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from timeit import default_timer as timer\n",
    "from torch.nn import Transformer\n",
    "from torch import Tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import tqdm\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textgrid\n",
    "from scipy.spatial.distance import euclidean\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import jiwer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import nltk\n",
    "nltk.download('cmudict')\n",
    "from nltk.corpus import cmudict\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "import soundfile as sf\n",
    "import pickle\n",
    "from scipy import stats\n",
    "_ESPEAK_LIBRARY = r\"C:\\Program Files\\eSpeak NG\\libespeak-ng.dll\"\n",
    "EspeakWrapper.set_library(_ESPEAK_LIBRARY)\n",
    "'''processor_P = AutoProcessor.from_pretrained(\"facebook/wav2vec2-lv-60-espeak-cv-ft\")\n",
    "model_P = AutoModelForCTC.from_pretrained(\"facebook/wav2vec2-lv-60-espeak-cv-ft\")'''\n",
    "\n",
    "# loading Hubert model\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "processor_H = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "model_H = AutoModelForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df=pd.read_csv(\"predicted_study1_TS_max1.csv\")\n",
    "predicted_df= predicted_df.rename(columns={'TrainingTalkerID1': 'TrainingTalkerID'})\n",
    "aggregated_data=predicted_df\n",
    "\n",
    "\n",
    "aggregated_data['TestTalkerID']-=2\n",
    "test_talkers = aggregated_data['TestTalkerID'].unique()\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "conditions = aggregated_data['Condition2'].unique()\n",
    "exposure_talkers = aggregated_data['TrainingTalkerID'].unique()\n",
    "talker_conditon=['Control', 'Multi-talker', 'Single talker', 'Talker-specific']\n",
    "color_palette=[\"gray\",\"limegreen\",\"blue\",\"red\"]\n",
    "shape_markers =  ['o', 's', 'D', '^', 'v', '<', '>', 'p', '*', 'h', 'x']#['o', 's', '^', 'D', 'P', '*']\n",
    "test_talkerID=[\"CMN_M_032\",\"CMN_M_043\",\"CMN_M_035\",\"CMN_M_037\"]\n",
    "condition_colors = {condition: color_palette[i] for i, condition in enumerate(conditions)}\n",
    "talker_shapes = {talker: shape_markers[i % len(shape_markers)] for i, talker in enumerate(exposure_talkers)}\n",
    "\n",
    "def apply_quantile_and_qcut(group):\n",
    "    group['similarity_bins'] = pd.qcut(group['similarity'], q=10, duplicates='drop')\n",
    "    return group\n",
    "\n",
    "def calculate_metrics(group):\n",
    "    mean_similarity = group['similarity'].mean()\n",
    "    weights=group['numCorrect']+group['numIncorrect']\n",
    "    #print(group)\n",
    "    weighted_accuracy = np.average(group['IsCorrect'], weights=weights)\n",
    "\n",
    "    ci_lower, ci_upper = stats.t.interval(0.95, len(group['IsCorrect']) - 1,\n",
    "                                           loc=weighted_accuracy,\n",
    "                                           scale=stats.sem(group['IsCorrect']))\n",
    "    return pd.Series({\n",
    "        'mean_similarity': mean_similarity,\n",
    "        'mean_accuracy': weighted_accuracy,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'response_count': group['numCorrect'].sum() \n",
    "    }, index=['mean_similarity', 'mean_accuracy', 'ci_lower', 'ci_upper', 'response_count'])\n",
    "def compute_ci(group):\n",
    "    mean = group.mean()\n",
    "    std_dev = group.std()\n",
    "    n = len(group)\n",
    "    ci = stats.norm.interval(0.95, loc=mean, scale=std_dev/np.sqrt(n))\n",
    "    return pd.Series([ci[0], ci[1]], index=['ci_low', 'ci_high'])\n",
    "aggregated_data = aggregated_data[aggregated_data['Condition2'] != 'Talker-specific']\n",
    "\n",
    "for ax, test_talker in zip(axes, test_talkers):\n",
    "    TS=predicted_df[predicted_df['TestTalkerID'] == test_talker]\n",
    "    TS=TS[TS['Condition2'] == 'Talker-specific']\n",
    "    TSgrouped = TS.groupby('TrainingTalkerID').agg(\n",
    "        similarity=('similarity','median'),\n",
    "        mean_isCorrect=('IsCorrect', 'mean'),\n",
    "        sum_numCorrect=('numCorrect', 'sum'),\n",
    "        ci_low=('IsCorrect', lambda x: np.mean(x) - stats.norm.ppf(0.975) * np.std(x) / np.sqrt(len(x))),\n",
    "        ci_high=('IsCorrect', lambda x: np.mean(x) + stats.norm.ppf(0.975) * np.std(x) / np.sqrt(len(x)))\n",
    "    ).reset_index()\n",
    "\n",
    "    ax.scatter(\n",
    "        x=TSgrouped['similarity'],\n",
    "        y=TSgrouped['mean_isCorrect'],\n",
    "        color=condition_colors[condition],\n",
    "        s=TSgrouped['sum_numCorrect']/10\n",
    "    )\n",
    "    ax.errorbar(\n",
    "        TSgrouped['similarity'],                           \n",
    "        TSgrouped['mean_isCorrect'],                            \n",
    "        yerr=[TSgrouped['mean_isCorrect'] - TSgrouped['ci_low'],  \n",
    "            TSgrouped['ci_high'] - TSgrouped['mean_isCorrect']],\n",
    "        fmt='none',                                          \n",
    "        color=condition_colors[condition],  \n",
    "        alpha=0.3                                   \n",
    "        #capsize=5,                                           \n",
    "        #label='95% CI'\n",
    "    )\n",
    "    \n",
    "    #continue\n",
    "    if aggregated_data['TestTalkerID'].all() != 'Talker-specific':\n",
    "        data = aggregated_data[aggregated_data['TestTalkerID'] == test_talker]\n",
    "        #data = apply_quantile_and_qcut(data)\n",
    "        #data['similarity_bins']=data['similarity_bins'].apply(lambda x: (x.left + x.right) / 2)\n",
    "        for condition in conditions:\n",
    "        #print(condition)\n",
    "            if condition!='Talker-specific':\n",
    "                condition_data = data[data['Condition2'] == condition]\n",
    "                for talker in set(condition_data[\"TrainingTalkerID\"]):\n",
    "                    talkerdata= condition_data[condition_data[\"TrainingTalkerID\"]==talker]\n",
    "                    talkerdata = apply_quantile_and_qcut(talkerdata)\n",
    "                    talkerdata['similarity_bins']=talkerdata['similarity_bins'].apply(lambda x: (x.left + x.right) / 2)\n",
    "                    '''grouped = talkerdata.groupby('similarity_bins').agg(\n",
    "                        mean_isCorrect=('IsCorrect', 'mean'),\n",
    "                        sum_numCorrect=('numCorrect', 'sum'),\n",
    "                        ci_low=('IsCorrect', lambda x: stats.norm.interval(0.95, loc=np.mean(x), scale=np.std(x)/np.sqrt(len(x)))[0]),\n",
    "                        ci_high=('IsCorrect', lambda x: stats.norm.interval(0.95, loc=np.mean(x), scale=np.std(x)/np.sqrt(len(x)))[1])\n",
    "                    ).reset_index()'''\n",
    "                    grouped = talkerdata.groupby('similarity_bins').agg(\n",
    "                        mean_isCorrect=('IsCorrect', 'mean'),\n",
    "                        sum_numCorrect=('numCorrect', 'sum'),\n",
    "                        ci_low=('IsCorrect', lambda x: np.mean(x) - stats.norm.ppf(0.975) * np.std(x) / np.sqrt(len(x))),\n",
    "                        ci_high=('IsCorrect', lambda x: np.mean(x) + stats.norm.ppf(0.975) * np.std(x) / np.sqrt(len(x)))\n",
    "                    ).reset_index()\n",
    "\n",
    "                    #ci_values = talkerdata.groupby('similarity_bins')['IsCorrect'].apply(compute_ci)\n",
    "                    #grouped = grouped.join(ci_values)\n",
    "                    #print(grouped)\n",
    "                    if condition == \"Single talker\":\n",
    "                        ax.scatter(\n",
    "                            x=grouped['similarity_bins'],\n",
    "                            y=grouped['mean_isCorrect'],\n",
    "                            color=condition_colors[condition],\n",
    "                            s=grouped['sum_numCorrect'],\n",
    "                            marker =talker_shapes[talker],\n",
    "                        )\n",
    "                    \n",
    "                    else:\n",
    "                        ax.scatter(\n",
    "                                x=grouped['similarity_bins'],\n",
    "                                y=grouped['mean_isCorrect'],\n",
    "                                color=condition_colors[condition],\n",
    "                                s=grouped['sum_numCorrect'],\n",
    "                                #marker =talker_shapes[test_talkerID[0]],\n",
    "                            )\n",
    "                    ax.errorbar(\n",
    "                        grouped['similarity_bins'],                           \n",
    "                        grouped['mean_isCorrect'],                            \n",
    "                        yerr=[grouped['mean_isCorrect'] - grouped['ci_low'],  \n",
    "                            grouped['ci_high'] - grouped['mean_isCorrect']],\n",
    "                        fmt='none',                                          \n",
    "                        color=condition_colors[condition],  \n",
    "                        alpha=0.3                                   \n",
    "                        #capsize=5,                                           \n",
    "                        #label='95% CI'\n",
    "                    )\n",
    "\n",
    "    for condition in conditions:\n",
    "        condition_data = data[data['Condition2'] == condition]\n",
    "        if condition == \"Single talker\":\n",
    "            for talker in exposure_talkers:\n",
    "                talker_data = condition_data[condition_data['TrainingTalkerID'] == talker]\n",
    "                if len(talker_data) > 1: \n",
    "\n",
    "                    sns.regplot(\n",
    "                        x='similarity',\n",
    "                        y='Predicted_Prob',\n",
    "                        data=talker_data,\n",
    "                        ax=ax,\n",
    "                        scatter=False,\n",
    "                        color=condition_colors[condition],\n",
    "                        line_kws={\"linestyle\": \"-\", \"alpha\": 0.3, \"linewidth\":2},\n",
    "                        label=f'{condition} fit ({talker})',\n",
    "                        #logx=True,\n",
    "                        logistic=True,\n",
    "                        #lowess=True,\n",
    "                        ci=95,\n",
    "                        #truncate=False\n",
    "                    )\n",
    "                    line = ax.get_lines()[-1]\n",
    "                    x_fit = line.get_xdata()\n",
    "                    y_fit = line.get_ydata()\n",
    "                    valid_indices = ~np.isnan(x_fit) & ~np.isinf(x_fit) & ~np.isnan(y_fit) & ~np.isinf(y_fit)\n",
    "                    x_fit = x_fit[valid_indices]\n",
    "                    y_fit = y_fit[valid_indices]\n",
    "        else:\n",
    "            if len(condition_data) > 1:\n",
    "                sns.regplot(\n",
    "                    x='similarity',\n",
    "                    y='Predicted_Prob',\n",
    "                    data=condition_data,\n",
    "                    ax=ax,\n",
    "                    scatter=False,\n",
    "                    color=condition_colors[condition],\n",
    "                    line_kws={\"linestyle\": \"-\", \"alpha\": 0.9,\"linewidth\":4},\n",
    "                    label=f'{condition} fit',\n",
    "                    logistic=True,\n",
    "                    #logx=True,\n",
    "                    #lowess=True,\n",
    "                    ci=95\n",
    "                )\n",
    "                \n",
    "                line = ax.get_lines()[-1]\n",
    "                x_fit = line.get_xdata()\n",
    "                y_fit = line.get_ydata()\n",
    "                valid_indices = ~np.isnan(x_fit) & ~np.isinf(x_fit) & ~np.isnan(y_fit) & ~np.isinf(y_fit)\n",
    "                x_fit = x_fit[valid_indices]\n",
    "                y_fit = y_fit[valid_indices]\n",
    "\n",
    "        \n",
    "    ax.set_title(f'Sample test talker {test_talkerID[test_talker-3]}', fontsize=14)\n",
    "    ax.set_xlabel('Exposure-to-test talker-similarity of keyword', fontsize=12)\n",
    "    ax.set_ylabel('Listener accuracy for keyword (mean)', fontsize=12)\n",
    "    ax.set_xlim(0.2,1.05)\n",
    "    ax.set_ylim(0.1,1.05)\n",
    "    ax.grid(alpha=0.3)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "condition_handles = [mlines.Line2D([], [], color=color, linestyle=\"-\", linewidth=2, label=f\"{condition}\")\n",
    "    for condition, color in condition_colors.items()\n",
    "]\n",
    "\n",
    "out=condition_handles\n",
    "fig.legend(\n",
    "    handles=out,\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, 0.96),\n",
    "    title=\"Condition line with colors\",#Talkers' shapes and \n",
    "    fontsize=9,\n",
    "    ncol=6\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.89])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BayesPCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
