{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JesseRinzel123/SSL-ASR-Cross-Talker-Generalization/blob/main/glmm_plot_Bradlow23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq && apt-get install -y -qq r-cran-lme4\n"
      ],
      "metadata": {
        "id": "0hIL_pmN8B61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#You need these code to allow colab access your google cloud space.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/ASR-Cross-Talker-Generalization')\n",
        "\n",
        "#It will bring up a new screen. Just follow the instructions."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbMcczXTjF-j",
        "outputId": "7da8764f-cab0-4b2c-980c-a8d85cf31037"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqgy_zzXjFLY",
        "outputId": "b2077ccc-522f-42ed-ece8-1bb904051c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textgrid in /usr/local/lib/python3.11/dist-packages (1.6.1)\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "!pip install textgrid\n",
        "import textgrid\n",
        "import itertools\n",
        "import multiprocessing\n",
        "import time\n",
        "from joblib import Parallel, delayed\n",
        "import pickle\n",
        "from rpy2.robjects.packages import importr\n",
        "from rpy2.robjects import Formula, pandas2ri\n",
        "\n",
        "import pandas as pd\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svlvQaN9jFLZ"
      },
      "source": [
        "### load audio file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "iQ6o3HNwjFLZ"
      },
      "outputs": [],
      "source": [
        "def get_pathset(paths):\n",
        "    return [os.path.join(dir, each_file) for dir, mid, files in os.walk(paths) for each_file in files if each_file.endswith(\".wav\")]\n",
        "audio_dir =\"data/speech_Bradlow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI1mjKP3jFLa"
      },
      "source": [
        "### load human data from xlsx file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "sh30JIDyjFLa"
      },
      "outputs": [],
      "source": [
        "human_result_path=\"data/BBP-2023-TestData2.xlsx\"\n",
        "human_result = pd.read_excel(human_result_path)\n",
        "human_result=human_result[human_result[\"training_condition\"]!=\"a_control\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RrxQPrzjFLa"
      },
      "source": [
        "### load 3d-tSNE representations from pkl file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "qSTCA3k8jFLa"
      },
      "outputs": [],
      "source": [
        "with open(\"data/hubert_T24.pkl\", \"rb\") as file:\n",
        "    tSNE_representations = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "nzB3RQgrjFLa"
      },
      "outputs": [],
      "source": [
        "from numba import njit\n",
        "@njit\n",
        "def weighted_minkowski(vec1, vec2,  tau, w=1):\n",
        "\n",
        "    total = 0.0\n",
        "    for m in range(len(vec1)):\n",
        "        diff = w*abs(vec1[m] - vec2[m])\n",
        "        total += (diff ** tau)\n",
        "    return total**(1/tau)#np.sqrt(total)\n",
        "\n",
        "@njit\n",
        "def dtw_sim(seq1, seq2,  tau, k):\n",
        "    n, m = len(seq1), len(seq2)\n",
        "    dtw_matrix = np.full((n+1, m+1), np.inf)\n",
        "    dtw_matrix[0, 0] = 0.0\n",
        "\n",
        "    for i in range(1, n+1):\n",
        "        for j in range(1, m+1):\n",
        "            cost = weighted_minkowski(seq1[i-1], seq2[j-1], tau)\n",
        "            dtw_matrix[i, j] = cost + min(dtw_matrix[i-1, j],    # insertion\n",
        "                                         dtw_matrix[i, j-1],    # deletion\n",
        "                                         dtw_matrix[i-1, j-1])  # match\n",
        "    return np.exp(-(dtw_matrix[n, m]/((n+m)/2))*k)# change to *k,\n",
        "\n",
        "\n",
        "def create_distance_matrix(sentence_matrix,tau, k):\n",
        "    distance_matirx=np.zeros((60,4,4))\n",
        "    for _,i in enumerate(sentence_matrix):\n",
        "        for _1,each_talker1 in enumerate(i):\n",
        "            for _2,each_talker2 in enumerate(i):\n",
        "                distance_matirx[_][_1][_2]=dtw_sim(each_talker1, each_talker2, tau, k)\n",
        "    return distance_matirx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "gwZ0B1OAjFLb"
      },
      "outputs": [],
      "source": [
        "def get_sentence_ind(audio_path,human_result):\n",
        "    tg = textgrid.TextGrid.fromFile(audio_path[:-3]+\"TextGrid\")\n",
        "    tg_sentence = [i for i in tg[0] if i.mark!=\"\"]\n",
        "    hint1=[]\n",
        "    for _,i in enumerate(tg_sentence):\n",
        "        if i.mark in set(human_result['sentence_test']):\n",
        "            hint1.append(_)\n",
        "    return hint1\n",
        "\n",
        "\n",
        "def sim_measure(df, distance_matirx,tg_sentence_list,talkers):\n",
        "    '''\n",
        "    This function is for computing the similarity values for each row of human data.\n",
        "    '''\n",
        "\n",
        "    out_df=pd.DataFrame(columns=['Condition', 'TrainingTalker', 'TestTalker','ListenerID' ,'Sentence',  'similarity', 'score_test_logit','numCorrect','numWord'])\n",
        "    for each_ in tqdm.tqdm(df.values):\n",
        "        if each_[1][0]==\"b\":\n",
        "            ind_T = talkers.index(each_[1][-3:])\n",
        "            arr = distance_matirx[tg_sentence_list.index(each_[df.columns.get_loc(\"sentence_test\")])][ind_T]\n",
        "            ind_test=talkers.index(each_[-3])\n",
        "            out_df.loc[len(out_df)]=[each_[df.columns.get_loc(\"st_mt_cnt\")],\n",
        "                                        each_[df.columns.get_loc(\"training_condition\")],\n",
        "                                        each_[df.columns.get_loc(\"speaker_test\")],\n",
        "                                        str(each_[df.columns.get_loc(\"id2\")]),\n",
        "                                        each_[df.columns.get_loc(\"sentence_test\")],\n",
        "                                        arr[ind_test],\n",
        "                                        each_[df.columns.get_loc(\"score_test_logit\")],\n",
        "                                        each_[df.columns.get_loc(\"score_test\")],\n",
        "                                        each_[df.columns.get_loc(\"possible_score_test\")]\n",
        "                                        ]\n",
        "        else:\n",
        "            ind_T = talkers.index(each_[1][-3:])\n",
        "            ind_test = talkers.index(each_[-3])\n",
        "            arr = distance_matirx[tg_sentence_list.index(each_[df.columns.get_loc(\"sentence_test\")])][ind_T]\n",
        "            #indices=np.nonzero(arr)\n",
        "            arr_non_1 = arr[arr!=1]\n",
        "            if each_[1][-3:] == each_[-3]:\n",
        "                out_df.loc[len(out_df)]=[each_[df.columns.get_loc(\"st_mt_cnt\")],\n",
        "                                         each_[df.columns.get_loc(\"training_condition\")],\n",
        "                                         each_[df.columns.get_loc(\"speaker_test\")],\n",
        "                                         str(each_[df.columns.get_loc(\"id2\")]),\n",
        "                                         each_[df.columns.get_loc(\"sentence_test\")],\n",
        "                                         np.mean(arr_non_1),\n",
        "                                         each_[df.columns.get_loc(\"score_test_logit\")],\n",
        "                                         each_[df.columns.get_loc(\"score_test\")],\n",
        "                                         each_[df.columns.get_loc(\"possible_score_test\")]\n",
        "                                         ]\n",
        "    return out_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faS7CWVsjFLb",
        "outputId": "9e3cd098-8efc-496e-a61a-f01cdd5336e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A BOY FELL FROM A WINDOW',\n",
              " 'BIG DOGS CAN BE DANGEROUS',\n",
              " 'THE SHOES WERE VERY DIRTY',\n",
              " 'THE PLAYER LOST A SHOE',\n",
              " \"SHE'S DRINKING FROM HER OWN CUP\",\n",
              " 'THE PICTURE CAME FROM A BOOK',\n",
              " 'THE CAR IS GOING TOO FAST',\n",
              " 'THE PAINT DRIPPED ON THE GROUND',\n",
              " 'THE TOWEL FELL ON THE FLOOR',\n",
              " 'THE KITCHEN WINDOW WAS CLEAN',\n",
              " 'THE MAILMAN BROUGHT A LETTER',\n",
              " 'THE MOTHER HEARD THE BABY',\n",
              " 'SHE FOUND HER PURSE IN THE TRASH',\n",
              " \"IT'S TIME TO GO TO BED\",\n",
              " 'MOTHER READ THE INSTRUCTIONS',\n",
              " 'THE DOG IS EATING SOME MEAT',\n",
              " 'THE PAINTER USES A BRUSH',\n",
              " 'SWIMMERS CAN HOLD THEIR BREATH',\n",
              " \"THEY'RE PUSHING AN OLD CAR\",\n",
              " 'THEY HAD TWO EMPTY BOTTLES',\n",
              " 'THE DOG SLEEPS IN A BASKET',\n",
              " \"THEY'RE PLAYING IN THE PARK\",\n",
              " 'THE BABY SLEPT ALL NIGHT',\n",
              " 'THE SALT SHAKER IS EMPTY',\n",
              " 'THE POLICEMAN KNOWS THE WAY',\n",
              " 'THE BUCKETS FILL UP QUICKLY',\n",
              " 'THE JANITOR SWEPT THE FLOOR',\n",
              " 'THE LADY WASHED THE SHIRT',\n",
              " 'THE MATCH BOXES ARE EMPTY',\n",
              " 'THE MAN IS PAINTING A SIGN',\n",
              " 'THE DOG CAME HOME AT LAST',\n",
              " 'THEY HEARD A FUNNY NOISE',\n",
              " 'THEY FOUND HIS BROTHER HIDING',\n",
              " 'THE DOG PLAYED WITH A STICK',\n",
              " 'THE BOOK TELLS A STORY',\n",
              " 'THE MATCHES ARE ON A SHELF',\n",
              " 'THE TEAM IS PLAYING WELL',\n",
              " 'THE SHIRTS ARE IN THE CLOSET',\n",
              " 'THEY WATCHED THE SCARY MOVIE',\n",
              " 'THE TALL MAN TIED HIS SHOES',\n",
              " 'A LETTER FELL ON THE FLOOR',\n",
              " 'THE BALL BOUNCED VERY HIGH',\n",
              " 'MOTHER CUT THE BIRTHDAY CAKE',\n",
              " 'THE FOOTBALL GAME IS OVER',\n",
              " 'SHE STOOD NEAR THE WINDOW',\n",
              " 'SHE USES HER SPOON TO EAT',\n",
              " 'THE CAT LAY ON THE BED',\n",
              " \"HE'S WASHING HIS FACE WITH SOAP\",\n",
              " 'THE DOG IS CHASING THE CAT',\n",
              " 'THE BABY HAS BLUE EYES',\n",
              " 'THE BAG FELL OFF THE SHELF',\n",
              " 'THEY KNOCKED ON THE WINDOW',\n",
              " 'THE FOOTBALL HIT THE GOALPOST',\n",
              " 'MOTHER GOT A SAUCEPAN',\n",
              " 'THE BABY WANTS HIS BOTTLE',\n",
              " 'THE BALL BROKE THE WINDOW',\n",
              " 'THE WAITER BROUGHT THE CREAM',\n",
              " 'THE GIRL IS WASHING HER HAIR',\n",
              " 'THE GIRL PLAYED WITH THE BABY',\n",
              " 'THEY ARE DRINKING COFFEE']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "audio_path=get_pathset(audio_dir)\n",
        "tg = textgrid.TextGrid.fromFile(audio_path[0][:-3]+\"TextGrid\")\n",
        "tg_sentence = [i for i in tg[0] if i.mark!=\"\"]\n",
        "hint1_list=get_sentence_ind(audio_path[0],human_result)\n",
        "tg_sentence=[tg_sentence[i].mark for i in hint1_list]\n",
        "tg1 = textgrid.TextGrid.fromFile(audio_path[1][:-3]+\"TextGrid\")\n",
        "tg_sentence1 = [i for i in tg1[0] if i.mark!=\"\"]\n",
        "hint2_list=get_sentence_ind(audio_path[1],human_result)\n",
        "tg_sentence1=[tg_sentence1[i].mark for i in hint2_list]\n",
        "tg_sentence_list=tg_sentence+tg_sentence1\n",
        "tg_sentence_list.index(human_result.values[0][human_result.columns.get_loc(\"sentence_test\")])\n",
        "tg_sentence_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "ps4jS0ppjFLb"
      },
      "outputs": [],
      "source": [
        "audio_path=get_pathset(audio_dir)\n",
        "talkers=[os.path.basename(i)[10:13] for i in audio_path if \"HT1\" in i]\n",
        "talkers=['BRP', 'FAR', 'TUR', 'SPA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "SPeVa_POjFLb"
      },
      "outputs": [],
      "source": [
        "def objective_function(params, sentence_matrix1, human_result, tg_sentence_list, talkers):\n",
        "    \"\"\"\n",
        "    compute the z-value based on our select parameters\n",
        "    \"\"\"\n",
        "    tau, k = params\n",
        "    similarity_matrix = create_distance_matrix(sentence_matrix1, tau, k)\n",
        "    out_df=sim_measure(human_result, similarity_matrix,tg_sentence_list,talkers)\n",
        "    out_df['numIncorrect'] = out_df['numWord'] - out_df['numCorrect']\n",
        "    out_df['prop_correct'] = out_df['numCorrect'] / out_df['numWord']\n",
        "\n",
        "\n",
        "    out_df['similarity_scaled'] = (out_df['similarity'] - np.mean(out_df['similarity'])) / (2 * np.std(out_df['similarity']))\n",
        "    mask_mt = (out_df[\"Condition\"] == \"mt\") & (out_df[\"TrainingTalker\"].str[-3:] == out_df[\"TestTalker\"])\n",
        "    mask_st = (out_df[\"Condition\"] == \"st \") & (out_df[\"TrainingTalker\"].str[-3:] != out_df[\"TestTalker\"])\n",
        "    new_df=out_df[mask_mt | mask_st]\n",
        "\n",
        "    if np.std(new_df['similarity']) < 0.01:\n",
        "        return {\n",
        "                    \"tau\": [tau],\n",
        "                    \"k\": [k],\n",
        "                    \"z-value\": [0],\n",
        "                    \"mean_sim\": [float(np.mean(new_df[\"similarity\"]))],\n",
        "                    \"sd_sim\": [float(np.std(new_df[\"similarity\"]))],\n",
        "                    \"error\": [\"std_sim<0.0001\"]  #\n",
        "                }\n",
        "    else:\n",
        "        try:\n",
        "            import rpy2.robjects as ro\n",
        "            import rpy2\n",
        "            from rpy2.robjects import pandas2ri\n",
        "            pandas2ri.activate()\n",
        "            base = importr('base')\n",
        "            stats = importr('stats')\n",
        "            lme4 = importr('lme4')\n",
        "            ro.r('options(warn=2)')\n",
        "            r_data = ro.conversion.py2rpy(new_df)\n",
        "            #r_data = pandas2ri.py2rpy(new_df)\n",
        "            formula = Formula('cbind(numCorrect, numIncorrect) ~ 1 + similarity_scaled + (1| TestTalker) + (1|Sentence)')\n",
        "            glmerControl = lme4.glmerControl(optimizer=\"bobyqa\", optCtrl=ro.vectors.ListVector({'maxfun': 1e6}))\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                    \"tau\": [tau],\n",
        "                    \"k\": [k],\n",
        "                    \"z-value\": [0],\n",
        "                    \"mean_sim\": [float(np.mean(new_df[\"similarity\"]))],\n",
        "                    \"sd_sim\": [float(np.std(new_df[\"similarity\"]))],\n",
        "                    \"error\": [e]  #\n",
        "                }\n",
        "        try:\n",
        "            model = lme4.glmer(formula, data=r_data, control=glmerControl, family=stats.binomial(link=\"logit\"))\n",
        "            #log_likelihood = ro.r['logLik'](model)\n",
        "            summary = base.summary(model)\n",
        "            coefficients = summary.rx2('coefficients')\n",
        "            z_value=coefficients[1][2]\n",
        "            return {\n",
        "                    \"tau\": [tau],\n",
        "                    \"k\": [k],\n",
        "                    \"z-value\": [z_value],\n",
        "                    \"mean_sim\": [float(np.mean(new_df[\"similarity\"]))],\n",
        "                    \"sd_sim\": [float(np.std(new_df[\"similarity\"]))],\n",
        "                    \"error\": [\"NA\"]  #\n",
        "                }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                    \"tau\": [tau],\n",
        "                    \"k\": [k],\n",
        "                    \"z-value\": [0],\n",
        "                    \"mean_sim\": [float(np.mean(new_df[\"similarity\"]))],\n",
        "                    \"sd_sim\": [float(np.std(new_df[\"similarity\"]))],\n",
        "                    \"error\": [str(e)]  #\n",
        "                }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ecOhM0VjFLb"
      },
      "outputs": [],
      "source": [
        "#change the tau and k range here:\n",
        "tau_values = 10**np.arange(-1,1.5,0.25)\n",
        "k_values = 10**np.arange(-4,2.5,0.5)\n",
        "\n",
        "#tau_values = 10**np.arange(-1,1,0.25)\n",
        "#k_values = 10**np.arange(-4,2.2,0.2)\n",
        "\n",
        "pandas2ri.activate()\n",
        "params_grid=list(itertools.product(tau_values, k_values))\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "n_jobs = min(31, multiprocessing.cpu_count())\n",
        "results = Parallel(n_jobs=n_jobs)(delayed(objective_function)(_, tSNE_representations, human_result, tg_sentence_list, talkers) for _ in params_grid)\n",
        "end_time = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpkySyyejFLb"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "def plot_gridsearch_result(results):\n",
        "    df = pd.json_normalize(results)\n",
        "    df['tau'] = df['tau'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
        "    df['k'] = df['k'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
        "    df['z-value'] = df['z-value'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
        "    df['mean_sim'] = df['mean_sim'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
        "    df['sd_sim'] = df['sd_sim'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
        "    tau_vals = tau_values\n",
        "    k_vals = k_values\n",
        "    tau_grid, k_grid = np.meshgrid(tau_vals, k_vals)\n",
        "\n",
        "\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=3,\n",
        "        subplot_titles=['z-value', 'mean_sim', 'sd_sim'],\n",
        "        specs=[[{'type': 'surface'}, {'type': 'surface'}, {'type': 'surface'}]]\n",
        "    )\n",
        "\n",
        "\n",
        "    z_grid = griddata((df['tau'], df['k']), df['z-value'], (tau_grid, k_grid), method='nearest')\n",
        "    mean_sim_grid = griddata((df['tau'], df['k']), df['mean_sim'], (tau_grid, k_grid), method='nearest')\n",
        "    sd_sim_grid = griddata((df['tau'], df['k']), df['sd_sim'], (tau_grid, k_grid), method='nearest')\n",
        "\n",
        "\n",
        "    fig.add_trace(go.Surface(z=z_grid, x=tau_grid, y=k_grid, colorscale='RdYlGn', showscale=False), row=1, col=1)\n",
        "    fig.add_trace(go.Surface(z=mean_sim_grid, x=tau_grid, y=k_grid, colorscale='RdYlGn', showscale=False), row=1, col=2)\n",
        "    fig.add_trace(go.Surface(z=sd_sim_grid, x=tau_grid, y=k_grid, colorscale='RdYlGn', showscale=False), row=1, col=3)\n",
        "\n",
        "\n",
        "    fig.update_layout(\n",
        "        width=1700,\n",
        "        height=600,\n",
        "        title='3D Surface Plots for z-value, mean_sim, and sd_sim from LSR of 24th-Transformer-layer (Bradlow 2023)',\n",
        "        scene=dict(\n",
        "            xaxis_title='Tau',\n",
        "            yaxis_title='K',\n",
        "            zaxis_title='Z-Value',\n",
        "            yaxis=dict(\n",
        "                type='log',\n",
        "                tickvals=[1e-4, 1e-3, 1e-2, 1e-1, 1, 10],\n",
        "                ticktext=['1e-4', '1e-3', '1e-2', '1e-1', '1', '10'],\n",
        "            )\n",
        "        ),\n",
        "        scene2=dict(\n",
        "            xaxis_title='Tau',\n",
        "            yaxis_title='K',\n",
        "            zaxis_title='Mean-Sim',\n",
        "            yaxis=dict(\n",
        "                type='log',\n",
        "                tickvals=[1e-4, 1e-3, 1e-2, 1e-1, 1, 10],\n",
        "                ticktext=['1e-4', '1e-3', '1e-2', '1e-1', '1', '10'],\n",
        "            )\n",
        "        ),\n",
        "        scene3=dict(\n",
        "            xaxis_title='Tau',\n",
        "            yaxis_title='K',\n",
        "            zaxis_title='SD-Sim',\n",
        "            yaxis=dict(\n",
        "                type='log',\n",
        "                tickvals=[1e-4, 1e-3, 1e-2, 1e-1, 1, 10],\n",
        "                ticktext=['1e-4', '1e-3', '1e-2', '1e-1', '1', '10'],\n",
        "            ),\n",
        "            zaxis=dict(\n",
        "                range=[0,0.5]\n",
        "            )\n",
        "        ),\n",
        "        showlegend=False,\n",
        "        coloraxis_showscale=False\n",
        "\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXkPRfgujFLc"
      },
      "outputs": [],
      "source": [
        "plot_gridsearch_result(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CStOQjKjFLc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJrY8y0_jFLc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFdY0c1PjFLc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNap1YcvjFLc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sfoneot1jFLc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMDOytSNjFLc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "BayesPCN",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}